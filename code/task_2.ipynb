{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for Coursework of GINT\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths to the file containing the samples with the processed features\n",
    "feature_of_counts = \"../processed_data/feature_vectors_counts.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv(feature_of_counts, index_col=0)\n",
    "X = dataset.iloc[:,1:9].values\n",
    "y = dataset.iloc[:, 9].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting (randomly) the dataset into the Training set and the (unseen) Test set\n",
    "# Note this is only for the first task of the coursework. You'll need a different approach for the other tasks, as they also need a validation stage in addition to the test with unseen data.\n",
    "# Also note the split is training 80% and test 20%) \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.astype(int), random_state=42, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a RF classifier\n",
    "clf = RandomForestClassifier() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model on the training dataset\n",
    "# fit function is used to train the model using the training sets as parameters\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing probability predictions on the test dataset\n",
    "scores_clf = clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_clf, tpr_clf, thresholds = metrics.roc_curve(y_test, scores_clf)\n",
    "AUC_clf = metrics.auc(fpr_clf, tpr_clf)\n",
    "pyplot.plot(fpr_clf,tpr_clf ,'r-')\n",
    "pyplot.xlabel(\"detector false positive rate\")\n",
    "pyplot.ylabel(\"detector true positive rate\")\n",
    "pyplot.title(f\"Detector ROC curve for Random Forest Classifier, the AUC is: {AUC_clf}\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Reg\n",
    "AUC_log_min = 0\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "for algorithm in ['lbfgs', 'newton-cg']:\n",
    "  for toleration in (1e-4, 1e-3,1e-2):\n",
    "    for regulation in (1e-1, 1e1):\n",
    "      for iter in (100, 1000):\n",
    "        log = LogisticRegression(solver = algorithm, tol = toleration, C= regulation, random_state = 23,  max_iter=iter).fit(X_train, y_train)\n",
    "        log.fit(X_train, y_train)\n",
    "        scores_log = log.predict_proba(X_test)[:,1]\n",
    "        AUC_log = metrics.roc_auc_score(y_test, scores_log)\n",
    "        print(AUC_log)\n",
    "        if AUC_log > AUC_log_min:\n",
    "          AUC_log_min = AUC_log\n",
    "          print(f\"Solver {algorithm!s}, toleration {toleration:g}, regulation {regulation:g}, itteration{iter:g} gives this AUC {AUC_log_min:g}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boost\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb= GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model on the training dataset\n",
    "# fit function is used to train the model using the training sets as parameters\n",
    "gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_gb = gb.predict_proba(X_test)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_gb, tpr_gb, thresholds = metrics.roc_curve(y_test, scores_gb)\n",
    "AUC_gb = metrics.auc(fpr_gb, tpr_gb)\n",
    "pyplot.plot(fpr_gb,tpr_gb ,'r-')\n",
    "pyplot.xlabel(\"detector false positive rate\")\n",
    "pyplot.ylabel(\"detector true positive rate\")\n",
    "pyplot.title(f\"Detector ROC curve for Gradient Boosting Classifier, The AUC is: {AUC_gb}\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc= AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model on the training dataset\n",
    "# fit function is used to train the model using the training sets as parameters\n",
    "abc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_abc = abc.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_abc, tpr_abc, thresholds = metrics.roc_curve(y_test, scores_abc)\n",
    "AUC_abc = metrics.auc(fpr_abc, tpr_abc)\n",
    "pyplot.plot(fpr_abc,tpr_abc ,'r-')\n",
    "pyplot.xlabel(\"detector false positive rate\")\n",
    "pyplot.ylabel(\"detector true positive rate\")\n",
    "pyplot.title(f\"Detector ROC curve for Ada Boost Classifier, The AUC is: {AUC_abc}\")\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
